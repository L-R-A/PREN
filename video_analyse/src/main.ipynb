{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preconditions\n",
    "\n",
    "import os\n",
    "import json\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import keras.api._v2.keras as keras\n",
    "from keras.applications import VGG16, ResNet50\n",
    "from keras.callbacks import EarlyStopping, TensorBoard\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras import regularizers\n",
    "import tensorflow as tf\n",
    "import random\n",
    "\n",
    "import helper as hp\n",
    "\n",
    "MODEL_NAME = \"v1_no_base_100000\" + \".keras\"\n",
    "MODEL_PATH = os.path.join(\"..\", \"tmp\", \"models\")\n",
    "\n",
    "RESSOURCES_PATH = os.path.join(\"..\", \"tmp\", \"train\", \"ressources\", \"bundle\")\n",
    "TRAIN_DATA_FOLDER = [\n",
    "    # \"1f7534fa-6ee2-4e6a-a921-2a635a5fe917\", \n",
    "    # \"9ef5620b-c769-49ba-b083-7cbc25fe7ec6\",\n",
    "    # \"56dd460c-200d-4248-b6d5-b61bd0681fd7\",\n",
    "    # \"81370b3a-0747-44f7-bdd9-08279027b99a\",\n",
    "    # \"470833f8-ddaf-4aca-8a65-e30f80504a8a\",\n",
    "    \"32831052-7914-4220-bde4-c970c9c6c404\",\n",
    "    \"82612320-658a-495f-9d10-e54b35471628\",\n",
    "    \"a04111fd-ac8f-44b4-b1af-fe8f67252098\",\n",
    "    \"b8768080-7bdd-43c1-ab11-b940b74b07ef\",\n",
    "    \"efc4db14-5e6b-4c14-8543-997997d55476\"\n",
    "]\n",
    "\n",
    "# Image properties\n",
    "IMAGE_HEIGHT_PX = 120\n",
    "IMAGE_WIDTH_PX = 160\n",
    "CROP_HEIGHT_PX = 5\n",
    "CROP_WIDTH_PX = 20\n",
    "\n",
    "NUM_CHANNELS = 3\n",
    "NUM_CLASSES = 4\n",
    "NUM_POSITIONS = 8\n",
    "\n",
    "color_mapping = { 'red': 0, 'yellow': 1, 'blue': 2, '': 3 }\n",
    "label_mapping = { 0: 'red', 1: 'yellow', 2: 'blue', 3: ''}\n",
    "\n",
    "NORMALIZE_VALUE = 255\n",
    "\n",
    "def map_labels_to_nummeric(label):\n",
    "    mapped_label = []\n",
    "\n",
    "    for pos in label.values():\n",
    "        mapped_label.append(color_mapping[pos])\n",
    "\n",
    "    return mapped_label\n",
    "\n",
    "# Normalize the images so that all values are between 0 and 1\n",
    "def normalize_images(images):\n",
    "    return images / NORMALIZE_VALUE\n",
    "\n",
    "\n",
    "# Data loading\n",
    "IN_DEBUG_MODE = False\n",
    "IMAGE_FOLDER = \"Images\"\n",
    "LABELS_FOLDER = \"Labels\"\n",
    "JSON_NAME = \"scene_results.json\"\n",
    "\n",
    "def get_data(stage):\n",
    "    labels = []\n",
    "    images = []\n",
    "\n",
    "    for train_folder in TRAIN_DATA_FOLDER:\n",
    "\n",
    "        scene_results_path = os.path.join(RESSOURCES_PATH, train_folder, stage, JSON_NAME)\n",
    "\n",
    "        if IN_DEBUG_MODE:\n",
    "            print(\"CURRENT STAGE: \" + stage + \"\\n\")\n",
    "            print(\"READING SCENE RESULTS AT: \" + scene_results_path)\n",
    "\n",
    "        with open(scene_results_path, 'r') as file:\n",
    "            scene_results = json.load(file)\n",
    "\n",
    "        for result in scene_results:\n",
    "\n",
    "            img = [];\n",
    "\n",
    "            image_not_found = False\n",
    "\n",
    "            if len(result[\"imagePaths\"]) != 2:\n",
    "                continue\n",
    "\n",
    "            for img_path in result[\"imagePaths\"]:\n",
    "\n",
    "                if IN_DEBUG_MODE:\n",
    "                    print(\"READING IMAGE AT: \" + img_path)\n",
    "\n",
    "                try:\n",
    "                    i = Image.open(os.path.join(RESSOURCES_PATH, train_folder, img_path))\n",
    "                except:\n",
    "                    image_not_found = True\n",
    "                    continue\n",
    "\n",
    "\n",
    "                # Scale down image (resize)\n",
    "                i = i.resize((IMAGE_WIDTH_PX, IMAGE_HEIGHT_PX))\n",
    "\n",
    "                # Channel order of Pillow is different than OpenCV\n",
    "                i = np.array(i)\n",
    "                i = hp.Preprocess.convert_to_BGR(i)\n",
    "\n",
    "                i = hp.Video.translate_image(i)\n",
    "\n",
    "                # Crop the image\n",
    "                i = i[0:115, 10:150]\n",
    "\n",
    "                i = hp.Augmentation.black_spots(i, 10)\n",
    "\n",
    "                i = hp.Preprocess.start(i)\n",
    "\n",
    "                img.append(i)\n",
    "\n",
    "            if image_not_found == False:\n",
    "                images.append(img)\n",
    "                try:\n",
    "                    # np.array(images) # is only necessary to check if the data is homogenous\n",
    "                    labels.append(result[\"positions\"])\n",
    "                except:\n",
    "                    print(f\"Images shape got inhomogenous at: ${result['imagePaths']}\")\n",
    "                    images.pop()\n",
    "\n",
    "        if IN_DEBUG_MODE:\n",
    "            print(\"\\n\\n\")\n",
    "    \n",
    "\n",
    "\n",
    "    return [np.array(images), np.array(labels)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base-Model generation\n",
    "LOSS_FUNCTION = 'categorical_crossentropy'\n",
    "\n",
    "input_branch_1 = keras.layers.Input(shape=(IMAGE_HEIGHT_PX - CROP_HEIGHT_PX, IMAGE_WIDTH_PX - CROP_WIDTH_PX, 3))\n",
    "input_branch_2 = keras.layers.Input(shape=(IMAGE_HEIGHT_PX - CROP_HEIGHT_PX, IMAGE_WIDTH_PX - CROP_WIDTH_PX, 3))\n",
    "\n",
    "# Shared convolutional layers for image processing\n",
    "convolutional_layers = [\n",
    "    keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "    keras.layers.MaxPooling2D((2, 2)),\n",
    "    keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    keras.layers.MaxPooling2D((2, 2)),\n",
    "    keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    keras.layers.MaxPooling2D((2, 2)),\n",
    "    keras.layers.Flatten()\n",
    "]\n",
    "\n",
    "# Process first image\n",
    "x1 = input_branch_1\n",
    "for layer in convolutional_layers:\n",
    "    x1 = layer(x1)\n",
    "\n",
    "# Process second image\n",
    "x2 = input_branch_2\n",
    "for layer in convolutional_layers:\n",
    "    x2 = layer(x2)\n",
    "\n",
    "x = keras.layers.Concatenate(axis=-1)([x1, x2])\n",
    "x = keras.layers.Dense(256, activation='relu')(x)\n",
    "x = keras.layers.Dropout(0.2)(x)\n",
    "x = keras.layers.Dense(NUM_POSITIONS * NUM_CLASSES, activation='softmax')(x)  # Output layer with 8 * 4 units\n",
    "\n",
    "output = keras.layers.Reshape((NUM_POSITIONS, NUM_CLASSES))(x)\n",
    "\n",
    "# Build the model with the two input branches and the output layer\n",
    "base_model = keras.models.Model(inputs=[input_branch_1, input_branch_2], outputs=output)\n",
    "\n",
    "optimizer = keras.optimizers.legacy.Adam(learning_rate=0.001)\n",
    "\n",
    "base_model.compile(optimizer=optimizer, loss=LOSS_FUNCTION, metrics=['accuracy', 'mean_squared_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Base model with VGG16\n",
    "\n",
    "# Input layers for the two images\n",
    "input_branch_1 = keras.layers.Input(shape=(IMAGE_HEIGHT_PX - CROP_HEIGHT_PX, IMAGE_WIDTH_PX - CROP_WIDTH_PX, 3))\n",
    "input_branch_2 = keras.layers.Input(shape=(IMAGE_HEIGHT_PX - CROP_HEIGHT_PX, IMAGE_WIDTH_PX - CROP_WIDTH_PX, 3))\n",
    "\n",
    "# Load the pre-trained VGG16 model (without the top layer)\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(IMAGE_HEIGHT_PX - CROP_HEIGHT_PX, IMAGE_WIDTH_PX - CROP_WIDTH_PX, 3))\n",
    "\n",
    "# Freeze the pre-trained layers (optional)\n",
    "for layer in base_model.layers:\n",
    "  layer.trainable = False\n",
    "\n",
    "# Extract features from both images using the VGG16 base model\n",
    "x1 = base_model(input_branch_1)\n",
    "x2 = base_model(input_branch_2)\n",
    "\n",
    "# Concatenate the extracted features\n",
    "x = keras.layers.Concatenate(axis=-1)([x1, x2])\n",
    "\n",
    "# Add custom layers for your specific task\n",
    "x = keras.layers.Flatten()(x)\n",
    "x = keras.layers.Dense(256, activation='relu', kernel_regularizer=regularizers.l2(0.001))(x)\n",
    "# x = keras.layers.Dropout(0.3)(x)\n",
    "x = keras.layers.Dense(NUM_POSITIONS * NUM_CLASSES, activation='softmax')(x)  # Output layer with 8 * 4 units\n",
    "\n",
    "# Final output layer for multi-class classification (adjust based on your problem)\n",
    "output = keras.layers.Reshape((NUM_POSITIONS, NUM_CLASSES))(x)\n",
    "\n",
    "# Create the final model with two inputs and one output\n",
    "base_model = keras.models.Model(inputs=[input_branch_1, input_branch_2], outputs=output)\n",
    "\n",
    "# Compile the model (adjust optimizer and loss function as needed)\n",
    "base_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy', 'mean_squared_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Base model with RESNET\n",
    "\n",
    "# Input layers for the two images\n",
    "input_branch_1 = keras.layers.Input(shape=(IMAGE_HEIGHT_PX - CROP_HEIGHT_PX, IMAGE_WIDTH_PX - CROP_WIDTH_PX, 3))\n",
    "input_branch_2 = keras.layers.Input(shape=(IMAGE_HEIGHT_PX - CROP_HEIGHT_PX, IMAGE_WIDTH_PX - CROP_WIDTH_PX, 3))\n",
    "\n",
    "# Load the pre-trained ResNET50 model (without the top layer)\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(IMAGE_HEIGHT_PX - CROP_HEIGHT_PX, IMAGE_WIDTH_PX - CROP_WIDTH_PX, 3))\n",
    "\n",
    "# Freeze the pre-trained layers (optional)\n",
    "for layer in base_model.layers:\n",
    "  layer.trainable = False\n",
    "\n",
    "# Extract features from both images using the ResNet50 base model\n",
    "x1 = base_model(input_branch_1)\n",
    "x2 = base_model(input_branch_2)\n",
    "\n",
    "# Concatenate the extracted features\n",
    "x = keras.layers.Concatenate(axis=-1)([x1, x2])\n",
    "\n",
    "# Add custom layers for your specific task\n",
    "x = keras.layers.Flatten()(x)\n",
    "x = keras.layers.Dense(256, activation='relu', kernel_regularizer=regularizers.l2(0.001))(x)\n",
    "# x = keras.layers.Dropout(0.3)(x)\n",
    "x = keras.layers.Dense(NUM_POSITIONS * NUM_CLASSES, activation='softmax')(x)  # Output layer with 8 * 4 units\n",
    "\n",
    "# Final output layer for multi-class classification (adjust based on your problem)\n",
    "output = keras.layers.Reshape((NUM_POSITIONS, NUM_CLASSES))(x)\n",
    "\n",
    "# Create the final model with two inputs and one output\n",
    "base_model = keras.models.Model(inputs=[input_branch_1, input_branch_2], outputs=output)\n",
    "\n",
    "# Compile the model (adjust optimizer and loss function as needed)\n",
    "base_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy', 'mean_squared_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-train existing model\n",
    "base_model = keras.models.load_model(os.path.join(MODEL_PATH, MODEL_NAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = get_data(\"Train\")\n",
    "verify_data = get_data(\"Verify\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1094/1094 [==============================] - 301s 275ms/step - loss: 0.0969 - accuracy: 0.9641 - mean_squared_error: 0.2090 - val_loss: 0.0312 - val_accuracy: 0.9901 - val_mean_squared_error: 0.2082 - lr: 2.5000e-04\n",
      "Epoch 2/50\n",
      "1094/1094 [==============================] - 340s 311ms/step - loss: 0.0755 - accuracy: 0.9719 - mean_squared_error: 0.2095 - val_loss: 0.0260 - val_accuracy: 0.9914 - val_mean_squared_error: 0.2088 - lr: 2.5000e-04\n",
      "Epoch 3/50\n",
      "1094/1094 [==============================] - 357s 326ms/step - loss: 0.0655 - accuracy: 0.9757 - mean_squared_error: 0.2099 - val_loss: 0.0243 - val_accuracy: 0.9917 - val_mean_squared_error: 0.2094 - lr: 2.5000e-04\n",
      "Epoch 4/50\n",
      "1094/1094 [==============================] - 349s 319ms/step - loss: 0.0573 - accuracy: 0.9788 - mean_squared_error: 0.2103 - val_loss: 0.0218 - val_accuracy: 0.9925 - val_mean_squared_error: 0.2097 - lr: 2.5000e-04\n",
      "Epoch 5/50\n",
      "1094/1094 [==============================] - 363s 331ms/step - loss: 0.0510 - accuracy: 0.9812 - mean_squared_error: 0.2105 - val_loss: 0.0209 - val_accuracy: 0.9926 - val_mean_squared_error: 0.2101 - lr: 2.5000e-04\n",
      "Epoch 6/50\n",
      "1094/1094 [==============================] - 388s 355ms/step - loss: 0.0477 - accuracy: 0.9826 - mean_squared_error: 0.2109 - val_loss: 0.0204 - val_accuracy: 0.9925 - val_mean_squared_error: 0.2101 - lr: 2.5000e-04\n",
      "Epoch 7/50\n",
      "1094/1094 [==============================] - 386s 353ms/step - loss: 0.0448 - accuracy: 0.9836 - mean_squared_error: 0.2111 - val_loss: 0.0207 - val_accuracy: 0.9928 - val_mean_squared_error: 0.2103 - lr: 2.5000e-04\n",
      "Epoch 8/50\n",
      "1094/1094 [==============================] - 373s 341ms/step - loss: 0.0404 - accuracy: 0.9853 - mean_squared_error: 0.2112 - val_loss: 0.0197 - val_accuracy: 0.9932 - val_mean_squared_error: 0.2106 - lr: 2.5000e-04\n",
      "Epoch 9/50\n",
      "1094/1094 [==============================] - 348s 318ms/step - loss: 0.0385 - accuracy: 0.9862 - mean_squared_error: 0.2114 - val_loss: 0.0186 - val_accuracy: 0.9937 - val_mean_squared_error: 0.2113 - lr: 2.5000e-04\n",
      "Epoch 10/50\n",
      "1094/1094 [==============================] - 372s 340ms/step - loss: 0.0371 - accuracy: 0.9866 - mean_squared_error: 0.2116 - val_loss: 0.0197 - val_accuracy: 0.9930 - val_mean_squared_error: 0.2110 - lr: 2.5000e-04\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, min_delta=0.01, restore_best_weights=True)\n",
    "learning_rate_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2)\n",
    "tensorboard_callback = TensorBoard(log_dir='./logs')\n",
    "\n",
    "IN_DEBUG_MODE = False\n",
    "EPOCS = 50\n",
    "\n",
    "def fit_model(model, train_data, verify_data):\n",
    "    train_images = normalize_images(np.array(train_data[0]))\n",
    "    numberic_train_labels = np.array([map_labels_to_nummeric(label) for label in train_data[1]])\n",
    "    train_labels = keras.utils.to_categorical(numberic_train_labels, num_classes=NUM_CLASSES)\n",
    "\n",
    "    verify_images = normalize_images(np.array((verify_data[0])))\n",
    "    numberic_verify_labels = np.array([map_labels_to_nummeric(label) for label in verify_data[1]])\n",
    "    verify_labels = keras.utils.to_categorical(numberic_verify_labels, num_classes=NUM_CLASSES)\n",
    "\n",
    "    if IN_DEBUG_MODE: \n",
    "        print(\"----- SHAPES ------\\n\")\n",
    "        print(f\"Train labels shape: {train_labels.shape}\")\n",
    "        print(f\"Train images shape: {train_images.shape}\")\n",
    "\n",
    "        print(f\"Verify labels shape: {verify_labels.shape}\")\n",
    "        print(f\"Verify images shape: {verify_images.shape}\\n\\n\")\n",
    "\n",
    "    model.fit(\n",
    "        [train_images[:, 0], train_images[:, 1]], train_labels, \n",
    "        epochs=EPOCS, \n",
    "        validation_data=([verify_images[:, 0], verify_images[:, 1]], verify_labels), verbose=1,\n",
    "        callbacks=[early_stopping, learning_rate_scheduler, tensorboard_callback])\n",
    "    \n",
    "    return model\n",
    "\n",
    "trained_model = fit_model(base_model, train_data, verify_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# v6 --> Dropout 20%, l2: 0.02\n",
    "# v7 --> Dropout 30%, l2: 0.002\n",
    "# v8 --> Dropout 0, l2: 0.002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save trained model \n",
    "trained_model.save(os.path.join(MODEL_PATH, MODEL_NAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "model = keras.models.load_model(os.path.join(MODEL_PATH, MODEL_NAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = get_data(\"Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 11s 70ms/step\n",
      "\n",
      "\n",
      "\n",
      "------ PREDICTION: Index 818 --------\n",
      "\n",
      "NUMMERIC: \n",
      "\n",
      "[1 1 2 3 3 0 3 3]\n",
      "READABLE: \n",
      "\n",
      "['yellow' 'yellow' 'blue' '' '' 'red' '' '']\n",
      "\n",
      "\n",
      "\n",
      "------ ACTUAL: Index 818 ------ \n",
      "\n",
      "NUMMERIC: \n",
      "\n",
      "[1 1 2 3 3 0 3 3]\n",
      "READABLE: \n",
      "\n",
      "['yellow' 'yellow' 'blue' '' '' 'red' '' '']\n"
     ]
    }
   ],
   "source": [
    "# Test model\n",
    "test_labels = np.array([map_labels_to_nummeric(label) for label in test_data[1]])\n",
    "\n",
    "if IN_DEBUG_MODE:\n",
    "    model.summary()\n",
    "\n",
    "test_images = normalize_images(np.array((test_data[0])))\n",
    "predictions = model.predict([test_images[:, 0], test_images[:, 1]])\n",
    "\n",
    "label_index = random.randint(0, len(test_labels)-1)\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "print(f\"------ PREDICTION: Index {label_index + 1} --------\\n\")\n",
    "predicted_nummeric = np.argmax(predictions, axis=-1)\n",
    "predicted_readable = np.vectorize(label_mapping.get)(predicted_nummeric)\n",
    "actual_readable = np.vectorize(label_mapping.get)(test_labels)\n",
    "\n",
    "\n",
    "print(\"NUMMERIC: \\n\")\n",
    "print(predicted_nummeric[label_index])\n",
    "print(\"READABLE: \\n\")\n",
    "print(predicted_readable[label_index])\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "print(f\"------ ACTUAL: Index {label_index + 1} ------ \\n\")\n",
    "print(\"NUMMERIC: \\n\")\n",
    "print(test_labels[label_index])\n",
    "print(\"READABLE: \\n\")\n",
    "print(actual_readable[label_index])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
