{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preconditions\n",
    "\n",
    "import os\n",
    "import json\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import keras.api._v2.keras as keras\n",
    "from keras.applications import VGG16, ResNet50\n",
    "from keras.callbacks import EarlyStopping, TensorBoard\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras import regularizers\n",
    "import tensorflow as tf\n",
    "\n",
    "import random\n",
    "import helper as hp\n",
    "\n",
    "MODEL_NAME = \"v1_no_base_50000\" + \".keras\"\n",
    "MODEL_PATH = os.path.join(\"..\", \"tmp\", \"models\")\n",
    "\n",
    "RESSOURCES_PATH = os.path.join(\"..\", \"tmp\", \"train\", \"ressources\", \"bundle\")\n",
    "TRAIN_DATA_FOLDER = [\n",
    "    \"1f7534fa-6ee2-4e6a-a921-2a635a5fe917\", \n",
    "    \"9ef5620b-c769-49ba-b083-7cbc25fe7ec6\",\n",
    "    \"56dd460c-200d-4248-b6d5-b61bd0681fd7\",\n",
    "    \"81370b3a-0747-44f7-bdd9-08279027b99a\",\n",
    "    \"470833f8-ddaf-4aca-8a65-e30f80504a8a\",\n",
    "    # \"32831052-7914-4220-bde4-c970c9c6c404\",\n",
    "    # \"82612320-658a-495f-9d10-e54b35471628\",\n",
    "    # \"a04111fd-ac8f-44b4-b1af-fe8f67252098\",\n",
    "    # \"b8768080-7bdd-43c1-ab11-b940b74b07ef\",\n",
    "    # \"efc4db14-5e6b-4c14-8543-997997d55476\"\n",
    "]\n",
    "\n",
    "# Image properties\n",
    "IMAGE_HEIGHT_PX = 120\n",
    "IMAGE_WIDTH_PX = 160\n",
    "CROP_HEIGHT_PX = 5\n",
    "CROP_WIDTH_PX = 20\n",
    "\n",
    "NUM_CHANNELS = 3\n",
    "NUM_CLASSES = 4\n",
    "NUM_POSITIONS = 8\n",
    "\n",
    "color_mapping = { 'red': 0, 'yellow': 1, 'blue': 2, '': 3 }\n",
    "label_mapping = { 0: 'red', 1: 'yellow', 2: 'blue', 3: ''}\n",
    "\n",
    "NORMALIZE_VALUE = 255\n",
    "\n",
    "def map_labels_to_nummeric(label):\n",
    "    mapped_label = []\n",
    "\n",
    "    for pos in label.values():\n",
    "        mapped_label.append(color_mapping[pos])\n",
    "\n",
    "    return mapped_label\n",
    "\n",
    "# Normalize the images so that all values are between 0 and 1\n",
    "def normalize_images(images):\n",
    "    return images / NORMALIZE_VALUE\n",
    "\n",
    "\n",
    "# Data loading\n",
    "IN_DEBUG_MODE = False\n",
    "IMAGE_FOLDER = \"Images\"\n",
    "LABELS_FOLDER = \"Labels\"\n",
    "JSON_NAME = \"scene_results.json\"\n",
    "\n",
    "def get_data(stage):\n",
    "    labels = []\n",
    "    images = []\n",
    "\n",
    "    for train_folder in TRAIN_DATA_FOLDER:\n",
    "\n",
    "        scene_results_path = os.path.join(RESSOURCES_PATH, train_folder, stage, JSON_NAME)\n",
    "\n",
    "        if IN_DEBUG_MODE:\n",
    "            print(\"CURRENT STAGE: \" + stage + \"\\n\")\n",
    "            print(\"READING SCENE RESULTS AT: \" + scene_results_path)\n",
    "\n",
    "        with open(scene_results_path, 'r') as file:\n",
    "            scene_results = json.load(file)\n",
    "\n",
    "        for result in scene_results:\n",
    "\n",
    "            img = [];\n",
    "\n",
    "            image_not_found = False\n",
    "\n",
    "            if len(result[\"imagePaths\"]) != 2:\n",
    "                continue\n",
    "\n",
    "            for img_path in result[\"imagePaths\"]:\n",
    "\n",
    "                if IN_DEBUG_MODE:\n",
    "                    print(\"READING IMAGE AT: \" + img_path)\n",
    "\n",
    "                try:\n",
    "                    i = Image.open(os.path.join(RESSOURCES_PATH, train_folder, img_path))\n",
    "                except:\n",
    "                    image_not_found = True\n",
    "                    continue\n",
    "\n",
    "\n",
    "                # Scale down image (resize)\n",
    "                i = i.resize((IMAGE_WIDTH_PX, IMAGE_HEIGHT_PX))\n",
    "\n",
    "                # Channel order of Pillow is different than OpenCV\n",
    "                i = np.array(i)\n",
    "                i = hp.Preprocess.convert_to_BGR(i)\n",
    "\n",
    "                i = hp.Video.translate_image(i)\n",
    "\n",
    "                # Crop the image\n",
    "                i = i[0:115, 10:150]\n",
    "\n",
    "                i = hp.Augmentation.black_spots(i, 10)\n",
    "\n",
    "                i = hp.Preprocess.start(i)\n",
    "\n",
    "                img.append(i)\n",
    "\n",
    "            if image_not_found == False:\n",
    "                images.append(img)\n",
    "                try:\n",
    "                    # np.array(images) # is only necessary to check if the data is homogenous\n",
    "                    labels.append(result[\"positions\"])\n",
    "                except:\n",
    "                    print(f\"Images shape got inhomogenous at: ${result['imagePaths']}\")\n",
    "                    images.pop()\n",
    "\n",
    "        if IN_DEBUG_MODE:\n",
    "            print(\"\\n\\n\")\n",
    "    \n",
    "\n",
    "\n",
    "    return [np.array(images), np.array(labels)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base-Model generation\n",
    "LOSS_FUNCTION = 'categorical_crossentropy'\n",
    "\n",
    "input_branch_1 = keras.layers.Input(shape=(IMAGE_HEIGHT_PX - CROP_HEIGHT_PX, IMAGE_WIDTH_PX - CROP_WIDTH_PX, 3))\n",
    "input_branch_2 = keras.layers.Input(shape=(IMAGE_HEIGHT_PX - CROP_HEIGHT_PX, IMAGE_WIDTH_PX - CROP_WIDTH_PX, 3))\n",
    "\n",
    "# Shared convolutional layers for image processing\n",
    "convolutional_layers = [\n",
    "    keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "    keras.layers.MaxPooling2D((2, 2)),\n",
    "    keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    keras.layers.MaxPooling2D((2, 2)),\n",
    "    keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    keras.layers.MaxPooling2D((2, 2)),\n",
    "    keras.layers.Flatten()\n",
    "]\n",
    "\n",
    "# Process first image\n",
    "x1 = input_branch_1\n",
    "for layer in convolutional_layers:\n",
    "    x1 = layer(x1)\n",
    "\n",
    "# Process second image\n",
    "x2 = input_branch_2\n",
    "for layer in convolutional_layers:\n",
    "    x2 = layer(x2)\n",
    "\n",
    "x = keras.layers.Concatenate(axis=-1)([x1, x2])\n",
    "x = keras.layers.Dense(256, activation='relu')(x)\n",
    "x = keras.layers.Dropout(0.2)(x)\n",
    "x = keras.layers.Dense(NUM_POSITIONS * NUM_CLASSES, activation='softmax')(x)  # Output layer with 8 * 4 units\n",
    "\n",
    "output = keras.layers.Reshape((NUM_POSITIONS, NUM_CLASSES))(x)\n",
    "\n",
    "# Build the model with the two input branches and the output layer\n",
    "base_model = keras.models.Model(inputs=[input_branch_1, input_branch_2], outputs=output)\n",
    "\n",
    "optimizer = keras.optimizers.legacy.Adam(learning_rate=0.001)\n",
    "\n",
    "base_model.compile(optimizer=optimizer, loss=LOSS_FUNCTION, metrics=['accuracy', 'mean_squared_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Base model with VGG16\n",
    "\n",
    "# Input layers for the two images\n",
    "input_branch_1 = keras.layers.Input(shape=(IMAGE_HEIGHT_PX - CROP_HEIGHT_PX, IMAGE_WIDTH_PX - CROP_WIDTH_PX, 3))\n",
    "input_branch_2 = keras.layers.Input(shape=(IMAGE_HEIGHT_PX - CROP_HEIGHT_PX, IMAGE_WIDTH_PX - CROP_WIDTH_PX, 3))\n",
    "\n",
    "# Load the pre-trained VGG16 model (without the top layer)\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(IMAGE_HEIGHT_PX - CROP_HEIGHT_PX, IMAGE_WIDTH_PX - CROP_WIDTH_PX, 3))\n",
    "\n",
    "# Freeze the pre-trained layers (optional)\n",
    "for layer in base_model.layers:\n",
    "  layer.trainable = False\n",
    "\n",
    "# Extract features from both images using the VGG16 base model\n",
    "x1 = base_model(input_branch_1)\n",
    "x2 = base_model(input_branch_2)\n",
    "\n",
    "# Concatenate the extracted features\n",
    "x = keras.layers.Concatenate(axis=-1)([x1, x2])\n",
    "\n",
    "# Add custom layers for your specific task\n",
    "x = keras.layers.Flatten()(x)\n",
    "x = keras.layers.Dense(256, activation='relu', kernel_regularizer=regularizers.l2(0.001))(x)\n",
    "# x = keras.layers.Dropout(0.3)(x)\n",
    "x = keras.layers.Dense(NUM_POSITIONS * NUM_CLASSES, activation='softmax')(x)  # Output layer with 8 * 4 units\n",
    "\n",
    "# Final output layer for multi-class classification (adjust based on your problem)\n",
    "output = keras.layers.Reshape((NUM_POSITIONS, NUM_CLASSES))(x)\n",
    "\n",
    "# Create the final model with two inputs and one output\n",
    "base_model = keras.models.Model(inputs=[input_branch_1, input_branch_2], outputs=output)\n",
    "\n",
    "# Compile the model (adjust optimizer and loss function as needed)\n",
    "base_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy', 'mean_squared_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Base model with RESNET\n",
    "\n",
    "# Input layers for the two images\n",
    "input_branch_1 = keras.layers.Input(shape=(IMAGE_HEIGHT_PX - CROP_HEIGHT_PX, IMAGE_WIDTH_PX - CROP_WIDTH_PX, 3))\n",
    "input_branch_2 = keras.layers.Input(shape=(IMAGE_HEIGHT_PX - CROP_HEIGHT_PX, IMAGE_WIDTH_PX - CROP_WIDTH_PX, 3))\n",
    "\n",
    "# Load the pre-trained ResNET50 model (without the top layer)\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(IMAGE_HEIGHT_PX - CROP_HEIGHT_PX, IMAGE_WIDTH_PX - CROP_WIDTH_PX, 3))\n",
    "\n",
    "# Freeze the pre-trained layers (optional)\n",
    "for layer in base_model.layers:\n",
    "  layer.trainable = False\n",
    "\n",
    "# Extract features from both images using the ResNet50 base model\n",
    "x1 = base_model(input_branch_1)\n",
    "x2 = base_model(input_branch_2)\n",
    "\n",
    "# Concatenate the extracted features\n",
    "x = keras.layers.Concatenate(axis=-1)([x1, x2])\n",
    "\n",
    "# Add custom layers for your specific task\n",
    "x = keras.layers.Flatten()(x)\n",
    "x = keras.layers.Dense(256, activation='relu', kernel_regularizer=regularizers.l2(0.001))(x)\n",
    "# x = keras.layers.Dropout(0.3)(x)\n",
    "x = keras.layers.Dense(NUM_POSITIONS * NUM_CLASSES, activation='softmax')(x)  # Output layer with 8 * 4 units\n",
    "\n",
    "# Final output layer for multi-class classification (adjust based on your problem)\n",
    "output = keras.layers.Reshape((NUM_POSITIONS, NUM_CLASSES))(x)\n",
    "\n",
    "# Create the final model with two inputs and one output\n",
    "base_model = keras.models.Model(inputs=[input_branch_1, input_branch_2], outputs=output)\n",
    "\n",
    "# Compile the model (adjust optimizer and loss function as needed)\n",
    "base_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy', 'mean_squared_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-train existing model\n",
    "base_model = keras.models.load_model(os.path.join(MODEL_PATH, MODEL_NAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = get_data(\"Train\")\n",
    "verify_data = get_data(\"Verify\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1094/1094 [==============================] - 313s 285ms/step - loss: 0.6050 - accuracy: 0.7402 - mean_squared_error: 0.2122 - val_loss: 0.2470 - val_accuracy: 0.9105 - val_mean_squared_error: 0.2048 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "1094/1094 [==============================] - 352s 322ms/step - loss: 0.2762 - accuracy: 0.8909 - mean_squared_error: 0.2073 - val_loss: 0.1452 - val_accuracy: 0.9479 - val_mean_squared_error: 0.2054 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "1094/1094 [==============================] - 353s 323ms/step - loss: 0.1971 - accuracy: 0.9235 - mean_squared_error: 0.2080 - val_loss: 0.1155 - val_accuracy: 0.9588 - val_mean_squared_error: 0.2057 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "1094/1094 [==============================] - 348s 318ms/step - loss: 0.1555 - accuracy: 0.9405 - mean_squared_error: 0.2084 - val_loss: 0.1028 - val_accuracy: 0.9633 - val_mean_squared_error: 0.2069 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "1094/1094 [==============================] - 366s 334ms/step - loss: 0.1284 - accuracy: 0.9517 - mean_squared_error: 0.2089 - val_loss: 0.0802 - val_accuracy: 0.9712 - val_mean_squared_error: 0.2080 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "1094/1094 [==============================] - 373s 341ms/step - loss: 0.1098 - accuracy: 0.9584 - mean_squared_error: 0.2092 - val_loss: 0.0689 - val_accuracy: 0.9752 - val_mean_squared_error: 0.2086 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "1094/1094 [==============================] - 365s 334ms/step - loss: 0.0974 - accuracy: 0.9633 - mean_squared_error: 0.2093 - val_loss: 0.0659 - val_accuracy: 0.9762 - val_mean_squared_error: 0.2085 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "1094/1094 [==============================] - 341s 312ms/step - loss: 0.0880 - accuracy: 0.9673 - mean_squared_error: 0.2096 - val_loss: 0.0661 - val_accuracy: 0.9758 - val_mean_squared_error: 0.2091 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "1094/1094 [==============================] - 360s 329ms/step - loss: 0.0800 - accuracy: 0.9704 - mean_squared_error: 0.2097 - val_loss: 0.0581 - val_accuracy: 0.9791 - val_mean_squared_error: 0.2092 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "1094/1094 [==============================] - 369s 337ms/step - loss: 0.0737 - accuracy: 0.9727 - mean_squared_error: 0.2098 - val_loss: 0.0590 - val_accuracy: 0.9784 - val_mean_squared_error: 0.2086 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "1094/1094 [==============================] - 374s 342ms/step - loss: 0.0673 - accuracy: 0.9755 - mean_squared_error: 0.2101 - val_loss: 0.0599 - val_accuracy: 0.9782 - val_mean_squared_error: 0.2100 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "1094/1094 [==============================] - 381s 349ms/step - loss: 0.0492 - accuracy: 0.9824 - mean_squared_error: 0.2106 - val_loss: 0.0428 - val_accuracy: 0.9845 - val_mean_squared_error: 0.2103 - lr: 5.0000e-04\n",
      "Epoch 13/50\n",
      "1094/1094 [==============================] - 382s 349ms/step - loss: 0.0442 - accuracy: 0.9842 - mean_squared_error: 0.2110 - val_loss: 0.0416 - val_accuracy: 0.9855 - val_mean_squared_error: 0.2108 - lr: 5.0000e-04\n",
      "Epoch 14/50\n",
      "1094/1094 [==============================] - 379s 347ms/step - loss: 0.0402 - accuracy: 0.9856 - mean_squared_error: 0.2111 - val_loss: 0.0453 - val_accuracy: 0.9835 - val_mean_squared_error: 0.2108 - lr: 5.0000e-04\n",
      "Epoch 15/50\n",
      "1094/1094 [==============================] - 382s 349ms/step - loss: 0.0390 - accuracy: 0.9859 - mean_squared_error: 0.2113 - val_loss: 0.0411 - val_accuracy: 0.9853 - val_mean_squared_error: 0.2114 - lr: 5.0000e-04\n",
      "Epoch 16/50\n",
      "1094/1094 [==============================] - 386s 353ms/step - loss: 0.0376 - accuracy: 0.9863 - mean_squared_error: 0.2111 - val_loss: 0.0422 - val_accuracy: 0.9850 - val_mean_squared_error: 0.2107 - lr: 5.0000e-04\n",
      "Epoch 17/50\n",
      "1094/1094 [==============================] - 386s 353ms/step - loss: 0.0366 - accuracy: 0.9868 - mean_squared_error: 0.2113 - val_loss: 0.0421 - val_accuracy: 0.9854 - val_mean_squared_error: 0.2116 - lr: 5.0000e-04\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, min_delta=0.01, restore_best_weights=True)\n",
    "learning_rate_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2)\n",
    "tensorboard_callback = TensorBoard(log_dir='./logs')\n",
    "\n",
    "IN_DEBUG_MODE = False\n",
    "EPOCS = 50\n",
    "\n",
    "def fit_model(model, train_data, verify_data):\n",
    "    train_images = normalize_images(np.array(train_data[0]))\n",
    "    numberic_train_labels = np.array([map_labels_to_nummeric(label) for label in train_data[1]])\n",
    "    train_labels = keras.utils.to_categorical(numberic_train_labels, num_classes=NUM_CLASSES)\n",
    "\n",
    "    verify_images = normalize_images(np.array((verify_data[0])))\n",
    "    numberic_verify_labels = np.array([map_labels_to_nummeric(label) for label in verify_data[1]])\n",
    "    verify_labels = keras.utils.to_categorical(numberic_verify_labels, num_classes=NUM_CLASSES)\n",
    "\n",
    "    if IN_DEBUG_MODE: \n",
    "        print(\"----- SHAPES ------\\n\")\n",
    "        print(f\"Train labels shape: {train_labels.shape}\")\n",
    "        print(f\"Train images shape: {train_images.shape}\")\n",
    "\n",
    "        print(f\"Verify labels shape: {verify_labels.shape}\")\n",
    "        print(f\"Verify images shape: {verify_images.shape}\\n\\n\")\n",
    "\n",
    "    model.fit(\n",
    "        [train_images[:, 0], train_images[:, 1]], train_labels, \n",
    "        epochs=EPOCS, \n",
    "        validation_data=([verify_images[:, 0], verify_images[:, 1]], verify_labels), verbose=1,\n",
    "        callbacks=[early_stopping, learning_rate_scheduler, tensorboard_callback])\n",
    "    \n",
    "    return model\n",
    "\n",
    "trained_model = fit_model(base_model, train_data, verify_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# v6 --> Dropout 20%, l2: 0.02\n",
    "# v7 --> Dropout 30%, l2: 0.002\n",
    "# v8 --> Dropout 0, l2: 0.002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save trained model \n",
    "trained_model.save(os.path.join(MODEL_PATH, MODEL_NAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "model = keras.models.load_model(os.path.join(MODEL_PATH, MODEL_NAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = get_data(\"Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 11s 70ms/step\n",
      "\n",
      "\n",
      "\n",
      "------ PREDICTION: Index 818 --------\n",
      "\n",
      "NUMMERIC: \n",
      "\n",
      "[1 1 2 3 3 0 3 3]\n",
      "READABLE: \n",
      "\n",
      "['yellow' 'yellow' 'blue' '' '' 'red' '' '']\n",
      "\n",
      "\n",
      "\n",
      "------ ACTUAL: Index 818 ------ \n",
      "\n",
      "NUMMERIC: \n",
      "\n",
      "[1 1 2 3 3 0 3 3]\n",
      "READABLE: \n",
      "\n",
      "['yellow' 'yellow' 'blue' '' '' 'red' '' '']\n"
     ]
    }
   ],
   "source": [
    "# Test model\n",
    "test_labels = np.array([map_labels_to_nummeric(label) for label in test_data[1]])\n",
    "\n",
    "if IN_DEBUG_MODE:\n",
    "    model.summary()\n",
    "\n",
    "test_images = normalize_images(np.array((test_data[0])))\n",
    "predictions = model.predict([test_images[:, 0], test_images[:, 1]])\n",
    "\n",
    "label_index = random.randint(0, len(test_labels)-1)\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "print(f\"------ PREDICTION: Index {label_index + 1} --------\\n\")\n",
    "predicted_nummeric = np.argmax(predictions, axis=-1)\n",
    "predicted_readable = np.vectorize(label_mapping.get)(predicted_nummeric)\n",
    "actual_readable = np.vectorize(label_mapping.get)(test_labels)\n",
    "\n",
    "\n",
    "print(\"NUMMERIC: \\n\")\n",
    "print(predicted_nummeric[label_index])\n",
    "print(\"READABLE: \\n\")\n",
    "print(predicted_readable[label_index])\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "print(f\"------ ACTUAL: Index {label_index + 1} ------ \\n\")\n",
    "print(\"NUMMERIC: \\n\")\n",
    "print(test_labels[label_index])\n",
    "print(\"READABLE: \\n\")\n",
    "print(actual_readable[label_index])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
