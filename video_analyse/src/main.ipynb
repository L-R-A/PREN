{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import keras.api._v2.keras as keras\n",
    "import random\n",
    "import helper as hp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"it_is_just_a_test\"\n",
    "MODEL_PATH = os.path.join(\"..\", \"tmp\", \"models\")\n",
    "\n",
    "RESSOURCES_PATH = os.path.join(\"..\", \"tmp\", \"train\", \"ressources\")\n",
    "TRAIN_DATA_FOLDER = \"data_02\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image properties\n",
    "IMAGE_HEIGHT_PX = 180\n",
    "IMAGE_WIDTH_PX = 320\n",
    "NUM_CHANNELS = 3\n",
    "NUM_CLASSES = 4\n",
    "NUM_POSITIONS = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_mapping = { 'red': 0, 'yellow': 1, 'blue': 2, '': 3 }\n",
    "label_mapping = { 0: 'red', 1: 'yellow', 2: 'blue', 3: ''}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "NORMALIZE_VALUE = 255\n",
    "\n",
    "def map_labels_to_nummeric(label):\n",
    "    mapped_label = []\n",
    "\n",
    "    for pos in label.values():\n",
    "        mapped_label.append(color_mapping[pos])\n",
    "\n",
    "    return mapped_label\n",
    "\n",
    "# Normalize the images so that all values are between 0 and 1\n",
    "def normalize_images(images):\n",
    "    return images / NORMALIZE_VALUE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base-Model generation\n",
    "LOSS_FUNCTION = 'categorical_crossentropy'\n",
    "\n",
    "input_branch_1 = keras.layers.Input(shape=(180, 320, 3))\n",
    "input_branch_2 = keras.layers.Input(shape=(180, 320, 3))\n",
    "\n",
    "# Shared convolutional layers for image processing\n",
    "convolutional_layers = [\n",
    "    keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "    keras.layers.MaxPooling2D((2, 2)),\n",
    "    keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    keras.layers.MaxPooling2D((2, 2)),\n",
    "    keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    keras.layers.MaxPooling2D((2, 2)),\n",
    "    keras.layers.Flatten()\n",
    "]\n",
    "\n",
    "# Process first image\n",
    "x1 = input_branch_1\n",
    "for layer in convolutional_layers:\n",
    "    x1 = layer(x1)\n",
    "\n",
    "# Process second image\n",
    "x2 = input_branch_2\n",
    "for layer in convolutional_layers:\n",
    "    x2 = layer(x2)\n",
    "\n",
    "x = keras.layers.Concatenate(axis=-1)([x1, x2])\n",
    "x = keras.layers.Dense(256, activation='relu')(x)\n",
    "x = keras.layers.Dropout(0.2)(x)\n",
    "x = keras.layers.Dense(NUM_POSITIONS * NUM_CLASSES, activation='softmax')(x)  # Output layer with 8 * 4 units\n",
    "\n",
    "output = keras.layers.Reshape((NUM_POSITIONS, NUM_CLASSES))(x)\n",
    "\n",
    "# Build the model with the two input branches and the output layer\n",
    "base_model = keras.models.Model(inputs=[input_branch_1, input_branch_2], outputs=output)\n",
    "\n",
    "optimizer = keras.optimizers.legacy.Adam(learning_rate=0.001)\n",
    "\n",
    "base_model.compile(optimizer=optimizer, loss=LOSS_FUNCTION, metrics=['accuracy', 'mean_squared_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loading\n",
    "IN_DEBUG_MODE = False\n",
    "IMAGE_FOLDER = \"Images\"\n",
    "LABELS_FOLDER = \"Labels\"\n",
    "JSON_NAME = \"scene_results.json\"\n",
    "\n",
    "def get_data(stage):\n",
    "    labels = []\n",
    "    images = []\n",
    "\n",
    "    scene_results_path = os.path.join(RESSOURCES_PATH, TRAIN_DATA_FOLDER, stage, JSON_NAME)\n",
    "\n",
    "    if IN_DEBUG_MODE:\n",
    "        print(\"CURRENT STAGE: \" + stage + \"\\n\")\n",
    "        print(\"READING SCENE RESULTS AT: \" + scene_results_path)\n",
    "\n",
    "    with open(scene_results_path, 'r') as file:\n",
    "        scene_results = json.load(file)\n",
    "\n",
    "    for result in scene_results:\n",
    "        img = [];\n",
    "\n",
    "        image_not_found = False\n",
    "\n",
    "        for img_path in result[\"imagePaths\"]:\n",
    "\n",
    "            if IN_DEBUG_MODE:\n",
    "                print(\"READING IMAGE AT: \" + img_path)\n",
    "\n",
    "            try:\n",
    "                i = Image.open(os.path.join(RESSOURCES_PATH, TRAIN_DATA_FOLDER, img_path))\n",
    "            except:\n",
    "                image_not_found = True\n",
    "                continue\n",
    "\n",
    "\n",
    "            # Scale down image (resize)\n",
    "            i = i.resize((IMAGE_WIDTH_PX, IMAGE_HEIGHT_PX))\n",
    "\n",
    "            # Channel order of Pillow is different than OpenCV\n",
    "            i = np.array(i)[:, :, ::-1]\n",
    "\n",
    "            i = hp.Preprocess.start(i)\n",
    "\n",
    "            img.append(i)\n",
    "\n",
    "        if image_not_found == False:\n",
    "            images.append(img)\n",
    "            try:\n",
    "                # np.array(images) # is only necessary to check if the data is homogenous\n",
    "                labels.append(result[\"positions\"])\n",
    "            except:\n",
    "                print(f\"Images shape got inhomogenous at: ${result['imagePaths']}\")\n",
    "                images.pop()\n",
    "\n",
    "            \n",
    "\n",
    "    if IN_DEBUG_MODE:\n",
    "        print(\"\\n\\n\")\n",
    "\n",
    "    return [np.array(images), np.array(labels)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 367ms/step - loss: 0.0272 - accuracy: 0.9821 - mean_squared_error: 0.2035 - val_loss: 4.6335 - val_accuracy: 0.3125 - val_mean_squared_error: 0.2210\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 300ms/step - loss: 0.0362 - accuracy: 0.9821 - mean_squared_error: 0.2073 - val_loss: 4.8053 - val_accuracy: 0.2500 - val_mean_squared_error: 0.2202\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 292ms/step - loss: 0.0033 - accuracy: 1.0000 - mean_squared_error: 0.2058 - val_loss: 4.9825 - val_accuracy: 0.2500 - val_mean_squared_error: 0.2197\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 305ms/step - loss: 0.0237 - accuracy: 0.9821 - mean_squared_error: 0.2094 - val_loss: 5.1503 - val_accuracy: 0.2500 - val_mean_squared_error: 0.2195\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 286ms/step - loss: 0.0017 - accuracy: 1.0000 - mean_squared_error: 0.2089 - val_loss: 5.3324 - val_accuracy: 0.2500 - val_mean_squared_error: 0.2194\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 297ms/step - loss: 0.0163 - accuracy: 1.0000 - mean_squared_error: 0.2099 - val_loss: 5.5145 - val_accuracy: 0.2500 - val_mean_squared_error: 0.2194\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 293ms/step - loss: 0.0779 - accuracy: 0.9821 - mean_squared_error: 0.2106 - val_loss: 5.5471 - val_accuracy: 0.2500 - val_mean_squared_error: 0.2191\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 280ms/step - loss: 0.0036 - accuracy: 1.0000 - mean_squared_error: 0.2077 - val_loss: 5.6047 - val_accuracy: 0.3125 - val_mean_squared_error: 0.2188\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 278ms/step - loss: 0.0028 - accuracy: 1.0000 - mean_squared_error: 0.2052 - val_loss: 5.6837 - val_accuracy: 0.3125 - val_mean_squared_error: 0.2186\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 298ms/step - loss: 0.0287 - accuracy: 0.9821 - mean_squared_error: 0.2033 - val_loss: 5.7509 - val_accuracy: 0.3125 - val_mean_squared_error: 0.2185\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "\n",
    "IN_DEBUG_MODE = False\n",
    "\n",
    "def fit_model(model, train_data, verify_data):\n",
    "    train_images = normalize_images(np.array(train_data[0]))\n",
    "    numberic_train_labels = np.array([map_labels_to_nummeric(label) for label in train_data[1]])\n",
    "    train_labels = keras.utils.to_categorical(numberic_train_labels, num_classes=NUM_CLASSES)\n",
    "\n",
    "    verify_images = normalize_images(np.array((verify_data[0])))\n",
    "    numberic_verify_labels = np.array([map_labels_to_nummeric(label) for label in verify_data[1]])\n",
    "    verify_labels = keras.utils.to_categorical(numberic_verify_labels, num_classes=NUM_CLASSES)\n",
    "\n",
    "    if IN_DEBUG_MODE: \n",
    "        print(\"----- SHAPES ------\\n\")\n",
    "        print(f\"Train labels shape: {train_labels.shape}\")\n",
    "        print(f\"Train images shape: {train_images.shape}\")\n",
    "\n",
    "        print(f\"Verify labels shape: {verify_labels.shape}\")\n",
    "        print(f\"Verify images shape: {verify_images.shape}\\n\\n\")\n",
    "\n",
    "    model.fit(\n",
    "        [train_images[:, 0], train_images[:, 1]], train_labels, \n",
    "        epochs=10, \n",
    "        validation_data=([verify_images[:, 0], verify_images[:, 1]], verify_labels), verbose=1)\n",
    "    \n",
    "    return model\n",
    "\n",
    "train_data = get_data(\"Train\")\n",
    "verify_data = get_data(\"Verify\")\n",
    "trained_model = fit_model(base_model, train_data, verify_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../tmp/models/it_is_just_a_test/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../tmp/models/it_is_just_a_test/assets\n"
     ]
    }
   ],
   "source": [
    "# Save trained model \n",
    "trained_model.save(os.path.join(MODEL_PATH, MODEL_NAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "model = keras.models.load_model(os.path.join(MODEL_PATH, MODEL_NAME))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 72ms/step\n",
      "\n",
      "\n",
      "\n",
      "------ PREDICTION: Index 1 --------\n",
      "\n",
      "NUMMERIC: \n",
      "\n",
      "[0 0 2 0 1 0 2 0]\n",
      "READABLE: \n",
      "\n",
      "['red' 'red' 'blue' 'red' 'yellow' 'red' 'blue' 'red']\n",
      "\n",
      "\n",
      "\n",
      "------ ACTUAL: Index 1 ------ \n",
      "\n",
      "NUMMERIC: \n",
      "\n",
      "[1 3 2 1 1 3 2 1]\n",
      "READABLE: \n",
      "\n",
      "['yellow' '' 'blue' 'yellow' 'yellow' '' 'blue' 'yellow']\n"
     ]
    }
   ],
   "source": [
    "# Test model\n",
    "test_data = get_data(\"Test\")\n",
    "test_labels = np.array([map_labels_to_nummeric(label) for label in test_data[1]])\n",
    "\n",
    "if IN_DEBUG_MODE:\n",
    "    model.summary()\n",
    "\n",
    "test_images = normalize_images(np.array((test_data[0])))\n",
    "predictions = model.predict([test_images[:, 0], test_images[:, 1]])\n",
    "\n",
    "label_index = random.randint(0, len(test_labels)-1)\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "print(f\"------ PREDICTION: Index {label_index + 1} --------\\n\")\n",
    "predicted_nummeric = np.argmax(predictions, axis=-1)\n",
    "predicted_readable = np.vectorize(label_mapping.get)(predicted_nummeric)\n",
    "\n",
    "actual_readable = np.vectorize(label_mapping.get)(test_labels)\n",
    "\n",
    "\n",
    "print(\"NUMMERIC: \\n\")\n",
    "print(predicted_nummeric[label_index])\n",
    "print(\"READABLE: \\n\")\n",
    "print(predicted_readable[label_index])\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "print(f\"------ ACTUAL: Index {label_index + 1} ------ \\n\")\n",
    "print(\"NUMMERIC: \\n\")\n",
    "print(test_labels[label_index])\n",
    "print(\"READABLE: \\n\")\n",
    "print(actual_readable[label_index])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
